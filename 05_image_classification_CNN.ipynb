{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/MQsJimorUbA1AgnGRUqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hpink97/tensorflow_keras_practice/blob/main/practice_covnets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "QDpf_RdmU0Tz"
      },
      "outputs": [],
      "source": [
        "##import libraries\n",
        "\n",
        "##tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
        "    formatter=dict(float=lambda x: \"%.3g\" % x))\n",
        "\n",
        "##file related libs\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import image_dataset_from_directory as import_img_dir\n",
        "from google.colab import files\n",
        "import os, shutil, pathlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1 : MNIST CNN with Maxpooling"
      ],
      "metadata": {
        "id": "6pLQWvg2t5qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "rYwzxRapY4G5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### show an example image\n",
        "n = int(np.random.choice(train_images.shape[0], 1, replace=False)  )\n",
        "example_digit = train_images[n]\n",
        "example_digit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIsLo9N_ZkDS",
        "outputId": "28fa3941-60c4-416a-90a2-91e2e8da077a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5, 110, 237,  87,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43, 178, 254, 254, 210,  38,  15,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 224, 254, 254, 254, 254, 254, 206,  85,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 142, 254, 254, 254, 254, 254, 254, 254, 242,  86,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 142, 254, 254, 254, 135, 100, 211, 254, 254, 212,  19,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6, 242, 254, 254, 222,  24,   0,  21, 210, 254, 254, 103,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3, 178, 254, 254, 197,   8,   0,   0,   0,  91, 254, 254, 171,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 108, 254, 254, 251, 122,   0,   0,   0,   0,  30, 254, 254, 218,  20,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  15, 187, 254, 254, 193,   0,   0,   0,   0,   0,  30, 254, 254, 241,  29,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 118, 254, 254, 254,  95,   0,   0,   0,   0,   0,  58, 254, 254, 171,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 208, 254, 254, 200,  22,   0,   0,   0,   0,  10, 230, 254, 254, 171,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  61, 247, 254, 249,  18,   0,   0,   0,   0,   0, 156, 255, 254, 230,  52,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 180, 254, 254, 196,   0,   0,   0,   0,   0, 156, 254, 254, 254, 189,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  59, 253, 254, 249,  13,   0,   0,   3,  49, 231, 254, 254, 254, 169,  37,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 172, 254, 254, 147,   0,   0,   5,  83, 254, 255, 254, 253, 211,  37,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  24, 226, 254, 254, 147,   2,  59, 181, 254, 254, 254, 254, 142,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  36, 254, 254, 254, 169, 186, 254, 254, 254, 254, 199, 136,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  36, 254, 254, 254, 254, 254, 254, 254, 235, 135,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  22, 222, 254, 254, 254, 254, 254, 171,  27,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  62, 254, 254, 254, 193,  17,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(example_digit, cmap=plt.cm.binary)\n",
        "plt.show()\n",
        "\n",
        "print(f\"image label ={train_labels[n]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "RzPmHtlnbHYI",
        "outputId": "170a7930-707d-4b4c-cd69-07aa59328c2a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image label =0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### reshape and scale data\n",
        "train_images = train_images.reshape((60000,28,28,1)).astype('float32')/255\n",
        "test_images = test_images.reshape((10000,28,28,1)).astype('float32')/255"
      ],
      "metadata": {
        "id": "NKesldtmdr2b"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initiate the convolutional neural network (CNN)\n",
        "\n",
        "\n",
        "*   Takes input tensor (image_height, image_width, image_channels)\n",
        "\n",
        "`Conv2D()` is the convolutional layer. This will split the input tensor into 2D windows of size `kernel_size * kernal_size`. In addition it will also compute `filters`, which is the depth of the layer's output tensor. These are no longer colour channels, but arbritary filters calculated by the layer...\n",
        "\n",
        "\n",
        "`MaxPooling2D` reduces the size of the output tensor, applying a hardcoded MAX transformation on 2*2 tensors. Allows information to be encoded on a larger proportion of the original input. Also reduces the complexity of the model, reducing compute and overfitting!!."
      ],
      "metadata": {
        "id": "MIbo9n38YAon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##initate a CovNet\n",
        "inputs = keras.Input(shape=(28,28,1)) #28*28 pixel black&white images\n",
        "my_layers = layers.Conv2D(filters=32, kernel_size=2, activation='relu')(inputs)\n",
        "my_layers = layers.MaxPooling2D(pool_size =2)(my_layers)\n",
        "my_layers = layers.Conv2D(filters=128, kernel_size=2, activation='relu')(my_layers)\n",
        "my_layers = layers.MaxPooling2D(pool_size =2)(my_layers)\n",
        "my_layers = layers.Conv2D(filters=256, kernel_size=3, activation='relu')(my_layers)\n",
        "my_layers = layers.MaxPooling2D(pool_size =2)(my_layers)\n",
        "my_layers = layers.Flatten()(my_layers)\n",
        "#mnist is 0-9, so output will be shape 10\n",
        "outputs= layers.Dense(10, activation ='softmax')(my_layers)\n",
        "covnet = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "##summarise model\n",
        "covnet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3quVeMVVD-v",
        "outputId": "f3f6239b-dc5a-4aeb-ffc1-3d27f9da0e7c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 27, 27, 32)        160       \n",
            "                                                                 \n",
            " max_pooling2d_48 (MaxPoolin  (None, 13, 13, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 12, 12, 128)       16512     \n",
            "                                                                 \n",
            " max_pooling2d_49 (MaxPoolin  (None, 6, 6, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " max_pooling2d_50 (MaxPoolin  (None, 2, 2, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 322,090\n",
            "Trainable params: 322,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "covnet.compile(optimizer='rmsprop',\n",
        "               loss='sparse_categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "covnet.fit(train_images, train_labels, epochs=8, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_P1SCCob1Kw",
        "outputId": "5ae732b3-8603-4747-87dc-fa8a763ab66a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "469/469 [==============================] - 4s 6ms/step - loss: 0.2115 - accuracy: 0.9347\n",
            "Epoch 2/8\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0525 - accuracy: 0.9836\n",
            "Epoch 3/8\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0337 - accuracy: 0.9893\n",
            "Epoch 4/8\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0237 - accuracy: 0.9923\n",
            "Epoch 5/8\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0180 - accuracy: 0.9944\n",
            "Epoch 6/8\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0133 - accuracy: 0.9957\n",
            "Epoch 7/8\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0107 - accuracy: 0.9968\n",
            "Epoch 8/8\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0081 - accuracy: 0.9975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f575c05de80>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc =covnet.evaluate(test_images, test_labels)\n",
        "print(f\"CovNet testing accuracy on MNIST = {test_acc*100:.3f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7OqjU2qe4-A",
        "outputId": "5c5e36f5-5988-4cc3-8899-9e6fbc70dbb2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.9902\n",
            "CovNet testing accuracy on MNIST = 99.020%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: Cats vs Dogs (2K samples)"
      ],
      "metadata": {
        "id": "c6CLQtcbua1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##import cat vs dogs kaggle competetion data\n",
        "\n",
        "\n",
        "#files.upload()\n",
        "#! mkdir ~/.kaggle/\n",
        "#! cp kaggle.json  ~/.kaggle/\n",
        "#! chmod 600 ~/.kaggle/kaggle.json\n",
        "#! kaggle competitions download -c dogs-vs-cats\n",
        "#!unzip -qq dogs-vs-cats.zip\n",
        "#! unzip -qq train.zip"
      ],
      "metadata": {
        "id": "3R3Kq2-MfFep"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def subset_images(subset_name, start_i, end_i):\n",
        "  for x in ('cat','dog'):\n",
        "    dir = new_dir/subset_name/x\n",
        "    if dir.exists() and dir.is_dir():\n",
        "      shutil.rmtree(dir)\n",
        "    os.makedirs(dir)\n",
        "    file_names = [f\"{x}.{i}.jpg\" for i in range(start_i, end_i)]\n",
        "    for jpg in file_names:\n",
        "      shutil.copyfile(src=orig_dir/jpg,\n",
        "                      dst = dir/jpg)\n",
        "      \n",
        "\n"
      ],
      "metadata": {
        "id": "j3b_hHjPz_8t"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_dir = pathlib.Path('train')\n",
        "new_dir = pathlib.Path('cats_vs_dogs_small')\n",
        "\n",
        "subset_images('train',0,1000)\n",
        "subset_images('validation',1000,1500)\n",
        "subset_images('test',1500,2500)\n",
        "\n",
        "!ls cats_vs_dogs_small/train/dog | head -10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-od2_-iP19pM",
        "outputId": "d44ac99a-9940-4098-9470-66cc56a72f26"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog.0.jpg\n",
            "dog.100.jpg\n",
            "dog.101.jpg\n",
            "dog.102.jpg\n",
            "dog.103.jpg\n",
            "dog.104.jpg\n",
            "dog.105.jpg\n",
            "dog.106.jpg\n",
            "dog.107.jpg\n",
            "dog.108.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cats_v_dogs_train = import_img_dir(\n",
        "    new_dir /'train',\n",
        "    image_size=(180,180),\n",
        "    batch_size =32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6v9Bv2S7ST5",
        "outputId": "1d05e9bb-c464-47d4-b4fe-af9c5784be53"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(180,180,3))\n",
        "x = layers.Rescaling(1./255)(inputs)##rescale to 0-1\n",
        "x = layers.Conv2D(filters=32,kernel_size=3,activation ='relu')(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64,kernel_size=3,activation ='relu')(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128,kernel_size=3,activation ='relu')(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256,kernel_size=3,activation ='relu')(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256,kernel_size=3,activation ='relu')(x)\n",
        "#x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "dog_cat_cnn = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "dog_cat_cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm-0TTQ27p22",
        "outputId": "7dcf9436-25eb-4121-a18f-cf54163c6dd0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_1 (Rescaling)     (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 178, 178, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 89, 89, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 87, 87, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 43, 43, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 41, 41, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 18, 18, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 9, 9, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 12545     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 991,041\n",
            "Trainable params: 991,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}