{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVKkmi2TkyxDVX4BsCuJ5k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hpink97/ML_notebooks/blob/main/CelebA_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI generate human faces using Generative Adversarial Networks (GANs)\n",
        "\n",
        "GANs work by training 2 models simoultaneously **(generator & discriminator)** - which are trying to fool each other... \n",
        "\n",
        "Generator acts as the artist. It takes in completley random inputs and attempts to general believable looking images. The discrimiator is a standard image classification model which attempts to tell real images from fake. \n",
        "\n",
        "In training the generator will become better at producing believable images, and the discrimator will become better at detecting the fake images, until an equilibrium is reached."
      ],
      "metadata": {
        "id": "1sXcZUOJMzvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#file manipulation\n",
        "import os\n",
        "import zipfile\n",
        "import random"
      ],
      "metadata": {
        "id": "FMRlGNShQWez"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import CelebA dataset - images of celebrities faces"
      ],
      "metadata": {
        "id": "XZ7Hy40nQuzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data_faces && wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-5cjpnGQt4p",
        "outputId": "8545c1e4-883c-4ee8-ef2b-19e3017bc94b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-14 08:33:21--  https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\n",
            "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.112.168\n",
            "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.112.168|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1443490838 (1.3G) [application/zip]\n",
            "Saving to: ‘celeba.zip’\n",
            "\n",
            "celeba.zip          100%[===================>]   1.34G  20.4MB/s    in 69s     \n",
            "\n",
            "2023-02-14 08:34:30 (20.0 MB/s) - ‘celeba.zip’ saved [1443490838/1443490838]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##unzip\n",
        "with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"data_faces/\")\n",
        "\n",
        "root = 'data_faces/img_align_celeba'\n",
        "img_list = os.listdir(root)\n",
        "print(len(img_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37A-rQxDSdOq",
        "outputId": "91a624e8-928a-4711-f423-9dadcdc51210"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(img_list)\n",
        "remove = img_list[75000:]\n",
        "for f in remove:\n",
        "    os.remove(os.path.join(root, f))\n",
        "\n",
        "img_list = os.listdir(root)\n",
        "print(len(img_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKAad-iVCoSA",
        "outputId": "847b7504-d884-4c35-e69e-3194ef9bb71a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##import datset using keras\n",
        "faces = keras.utils.image_dataset_from_directory(\n",
        "    root,\n",
        "    ##don't care about original labels - for our GAN they'll all be labelled REAL\n",
        "    label_mode = None, \n",
        "    ##resize image to 64*64 - limited GPU!!\n",
        "    image_size = (64,64),\n",
        "    batch_size = 32, \n",
        "    smart_resize = True \n",
        ")\n",
        "\n",
        "##show sample face\n",
        "for batch in faces:\n",
        "  face = batch.numpy().astype('int32')[12]\n",
        "  plt.axis('off')\n",
        "  plt.imshow(face)\n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "kfgmCBp4TLAZ",
        "outputId": "a01468d0-ae29-4396-9af4-57ac1a82d4c6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 75000 files belonging to 1 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5Q8NmGXNZ7N",
        "outputId": "b40e4821-cfc4-4711-abd2-0d10caa86e6d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##scale values to 0-1\n",
        "faces=faces.map(lambda x:x/255.) #scale between 0-1\n"
      ],
      "metadata": {
        "id": "1_qUBHnSVlWG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAN Discriminator - classify real vs fake images\n",
        "\n",
        "Striding seems to work better in GANs than MaxPooling. Also using LeakyReLU seems to also work better..."
      ],
      "metadata": {
        "id": "QjFxxsaGV90b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "    keras.Input(shape=(64,64,3)), #input an image\n",
        "    layers.Conv2D(filters =64, kernel_size = 4, strides=2, padding = 'same'), \n",
        "    layers.LeakyReLU(alpha=0.2),\n",
        "    layers.Conv2D(filters =128, kernel_size = 4, strides=2, padding = 'same'), \n",
        "    layers.LeakyReLU(alpha=0.2),\n",
        "    layers.Conv2D(filters =128, kernel_size = 4, strides=2, padding = 'same'), \n",
        "    layers.LeakyReLU(alpha=0.2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "    ],\n",
        "    name = 'discriminator',\n",
        ")\n",
        "\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzCB8Um3V41q",
        "outputId": "37314c9e-773b-4131-a157-3933b3be6146"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 64)        3136      \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 128)       131200    \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 8, 8, 128)         262272    \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 8193      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 404,801\n",
            "Trainable params: 404,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAN Generator \n",
        "\n",
        "This model will accept a random nornally distributed vector (**latent space**) as input, and generate a 64x64x3 image as output. Image will be noise to start with, but after training of model weights image should resemble a human face. \n",
        "\n",
        "**`Conv2DTranspose `** layers will be used to perform **deconvolution** (opposite on convolution), to generate the images. \n",
        "\n",
        "Kernel size of `Conv2dTransponse` layers **MUST** be divisible by stride size to avoid checkboard artifacts (linked to unequal coverage of pixel space by generator) \n",
        "\n",
        "`strides = 2` causes Output height x width to half in each `Conv2D layer` and dounle in each `Conv2DTransponse` layer. Important as generator model needs to reverse the dimensions of the discriminator (in order to end up with a 64x64x3 image)"
      ],
      "metadata": {
        "id": "zrKQA4zoZukq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_space_dim = 128 \n",
        "\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_space_dim,)),\n",
        "    ##should be same dimension of discriminators flattened layer (8192)\n",
        "        layers.Dense(8*8*128), \n",
        "     ##reverse flattening - get back to output shape from last Conv2D layer\n",
        "        layers.Reshape((8,8,128)),\n",
        "     ##start deconvolution \n",
        "        layers.Conv2DTranspose(128, kernel_size =4, strides=2, padding ='same'),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(256, kernel_size =4, strides=2, padding ='same'),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size =4, strides=2, padding ='same'),\n",
        "        layers.LeakyReLU(alpha=0.2), \n",
        "        layers.Conv2D(filters = 3, ##reverts back to 3 channel image\n",
        "                      kernel_size = 5, \n",
        "                      padding = 'same',\n",
        "                      activation = 'sigmoid'),\n",
        "     ], name = 'generator'\n",
        ")\n",
        "\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cyl4esVZtYv",
        "outputId": "e5fbe74e-dc9a-4dc3-c1eb-167b1de56dee"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 8192)              1056768   \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 16, 16, 128)      262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 32, 32, 256)      524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 64, 64, 512)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 64, 64, 3)         38403     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,979,651\n",
            "Trainable params: 3,979,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adversiral Network - combine discriminator and generator in a model"
      ],
      "metadata": {
        "id": "7TFZSXbUiK1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##devlop GAN class inheriting from keras model\n",
        "class GAN(keras.Model):\n",
        "  def __init__(self, discriminator, generator, latent_space_dim):\n",
        "    super().__init__()\n",
        "    #add the two models\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.latent_dim = latent_space_dim\n",
        "    ##define loss metrics for discriminator and generator\n",
        "    self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n",
        "    self.g_loss_metric = keras.metrics.Mean(name= 'g_loss')\n",
        "  \n",
        "  def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "    super(GAN, self).compile()\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.loss_fn = loss_fn\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    m = [self.d_loss_metric, self.g_loss_metric]\n",
        "    return m\n",
        "\n",
        "  ###define function for training the combined model\n",
        "  def train_step(self, real_img):\n",
        "    batch_size = tf.shape(real_img)[0]\n",
        "    latent_vector = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "    #print('make some fake images')\n",
        "    #use generator to produce fake images\n",
        "    fake_img = self.generator(latent_vector)\n",
        "    all_imgs = tf.concat([fake_img, real_img],axis=0)\n",
        "\n",
        "    labels = tf.concat([\n",
        "        tf.ones(shape=(batch_size, 1)),\n",
        "        tf.zeros(shape=(batch_size,1))\n",
        "    ],axis =0)\n",
        "\n",
        "    ##add some random noise to labels - because magic???\n",
        "    labels += 0.05* tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "    #####################train the discriminator#######################\n",
        "    with tf.GradientTape() as d_tape:\n",
        "      pred_class = self.discriminator(all_imgs)\n",
        "      d_loss = self.loss_fn(labels, pred_class)\n",
        "    ##extract trainable weights and 9\n",
        "    d_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "    self.d_optimizer.apply_gradients(\n",
        "        zip(d_gradients,self.discriminator.trainable_weights)\n",
        "    )\n",
        "\n",
        "    ###################train the generator ##########################\n",
        "\n",
        "    latent_vector2 = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "    ##incorrectly tell generator all images are real....\n",
        "    misleading_labels = tf.zeros(shape=(batch_size,1))\n",
        "\n",
        "    with tf.GradientTape() as g_tape:\n",
        "      fake_img2 = self.generator(latent_vector2)\n",
        "      ##predict class of new fake images with discriminator \n",
        "      pred_class2 = self.discriminator(fake_img2)\n",
        "      ##calculate loss discriminator predictions vs all images being real (isn't actually true)\n",
        "      ##however, when gradients are update to minimise loss...\n",
        "      ##we'll make images discriminator are more likely to think is true\n",
        "      g_loss = self.loss_fn(misleading_labels, pred_class2)\n",
        "    \n",
        "    g_gradients = g_tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "    self.g_optimizer.apply_gradients(\n",
        "        zip(g_gradients, self.generator.trainable_weights)\n",
        "    )\n",
        "\n",
        "    ################update loss##################\n",
        "    self.d_loss_metric.update_state(d_loss)\n",
        "    self.g_loss_metric.update_state(g_loss)\n",
        "\n",
        "    loss_dict = {\"d_loss\":self.d_loss_metric.result(),\n",
        "                 \"g_loss\":self.g_loss_metric.result()}\n",
        "\n",
        "    return loss_dict\n",
        "                 \n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "fL-ULOXyiT-z"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "  def __init__(self, num_img =3, latent_dim = latent_space_dim):\n",
        "    self.num_img=3\n",
        "    self.latent_dim = latent_dim\n",
        "  \n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    latent_vector = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "    new_imgs = self.model.generator(latent_vector)\n",
        "    new_imgs *=255\n",
        "    new_imgs.numpy()\n",
        "    for n in range(self.num_img):\n",
        "      img=keras.utils.array_to_img(new_imgs[n])\n",
        "      img.save(f\"GAN_image_epoch{epoch:03d}_image_{n}.png\")"
      ],
      "metadata": {
        "id": "6FRNJ21cIl9O"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's train this mf"
      ],
      "metadata": {
        "id": "013OTxaQK4KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = GAN(discriminator=discriminator,\n",
        "            generator= generator, \n",
        "            latent_space_dim = latent_space_dim)\n",
        "\n",
        "model.compile(d_optimizer= tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              g_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss_fn = keras.losses.BinaryCrossentropy(),\n",
        "              )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vMFbl0CwK3bH"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(faces,\n",
        "          epochs=100,\n",
        "          callbacks=[GANMonitor(num_img=4, latent_dim=latent_space_dim)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZZm4JUPSfdW",
        "outputId": "9b5ec8ac-e34c-40af-84bb-3abc8043913f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "make some fake images\n",
            "make some fake images\n",
            "6332/6332 [==============================] - 1746s 275ms/step - d_loss: 0.5955 - g_loss: 1.2677\n",
            "Epoch 2/100\n",
            "6332/6332 [==============================] - 1755s 277ms/step - d_loss: 0.6416 - g_loss: 1.1101\n",
            "Epoch 3/100\n",
            "6332/6332 [==============================] - 1760s 278ms/step - d_loss: 0.6633 - g_loss: 1.0151\n",
            "Epoch 4/100\n",
            "6332/6332 [==============================] - 1759s 278ms/step - d_loss: 0.6400 - g_loss: 1.0859\n",
            "Epoch 5/100\n",
            "6332/6332 [==============================] - 1764s 279ms/step - d_loss: 0.6379 - g_loss: 1.1055\n",
            "Epoch 6/100\n",
            "6332/6332 [==============================] - 1762s 278ms/step - d_loss: 0.6472 - g_loss: 1.0126\n",
            "Epoch 7/100\n",
            "2776/6332 [============>.................] - ETA: 16:38 - d_loss: 0.6664 - g_loss: 0.9416"
          ]
        }
      ]
    }
  ]
}